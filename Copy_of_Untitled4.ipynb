{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdC9Z556cflxKC1jm8WR9d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kellozr/MINIproject1/blob/main/Copy_of_Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "cwG-137Tlgxz",
        "outputId": "c02d2161-0177-4930-fa89-b73eeaf4f94f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bfd6502da4f0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import kagglehub\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Download the dataset\n",
        "path = kagglehub.dataset_download(\"iarunava/cell-images-for-detecting-malaria\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Set image size\n",
        "width = 128\n",
        "height = 128\n",
        "\n",
        "# Load and explore the dataset\n",
        "infected_folder = path + '/cell_images/Parasitized/'\n",
        "uninfected_folder = path + '/cell_images/Uninfected/'\n",
        "\n",
        "print(\"Infected images:\", len(os.listdir(infected_folder)))\n",
        "print(\"Uninfected images:\", len(os.listdir(uninfected_folder)))\n",
        "\n",
        "# Sample Infected and Uninfected Images\n",
        "rand_inf = np.random.randint(0, len(os.listdir(infected_folder)))\n",
        "inf_pic = os.listdir(infected_folder)[rand_inf]\n",
        "\n",
        "rand_uninf = np.random.randint(0, len(os.listdir(uninfected_folder)))\n",
        "uninf_pic = os.listdir(uninfected_folder)[rand_uninf]\n",
        "\n",
        "# Load the images\n",
        "inf_load = Image.open(infected_folder + inf_pic)\n",
        "uninf_load = Image.open(uninfected_folder + uninf_pic)\n",
        "\n",
        "# Plot the images\n",
        "f = plt.figure(figsize=(10, 6))\n",
        "\n",
        "a1 = f.add_subplot(1, 2, 1)\n",
        "plt.imshow(inf_load)\n",
        "a1.set_title('Infected cell')\n",
        "\n",
        "a2 = f.add_subplot(1, 2, 2)\n",
        "plt.imshow(uninf_load)\n",
        "a2.set_title('Uninfected cell')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Dividing data into training and validation sets\n",
        "datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.2)\n",
        "\n",
        "# Train Data\n",
        "trainDatagen = datagen.flow_from_directory(directory=path + '/cell_images/',\n",
        "                                           target_size=(width, height),\n",
        "                                           class_mode='binary',\n",
        "                                           batch_size=16,\n",
        "                                           subset='training')\n",
        "\n",
        "# Validation Data\n",
        "valDatagen = datagen.flow_from_directory(directory=path + '/cell_images/',\n",
        "                                         target_size=(width, height),\n",
        "                                         class_mode='binary',\n",
        "                                         batch_size=16,\n",
        "                                         subset='validation')\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "cnn_model = model.fit(trainDatagen,\n",
        "                      steps_per_epoch=len(trainDatagen),\n",
        "                      epochs=20,\n",
        "                      validation_data=valDatagen,\n",
        "                      validation_steps=len(valDatagen))\n",
        "\n",
        "# Plot the accuracy and loss graphs\n",
        "plt.plot(cnn_model.history['accuracy'])\n",
        "plt.plot(cnn_model.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training set', 'Validation set'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cnn_model.history['loss'])\n",
        "plt.plot(cnn_model.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training set', 'Test set'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Dataset Setup - Replace the 'dataset_download' with your specific dataset location or direct download\n",
        "# Kaggle Hub will provide the path to the dataset after downloading\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"iarunava/cell-images-for-detecting-malaria\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Set image size\n",
        "width = 128\n",
        "height = 128\n",
        "\n",
        "# Directories for the dataset\n",
        "infected_folder = '../input/cell-images-for-detecting-malaria/cell_images/Parasitized/'\n",
        "uninfected_folder = '../input/cell-images-for-detecting-malaria/cell_images/Uninfected/'\n",
        "\n",
        "# Check dataset sizes\n",
        "print(\"Infected images count:\", len(os.listdir(infected_folder)))\n",
        "print(\"Uninfected images count:\", len(os.listdir(uninfected_folder)))\n",
        "\n",
        "# Display sample images\n",
        "rand_inf = np.random.randint(0, len(os.listdir(infected_folder)))\n",
        "inf_pic = os.listdir(infected_folder)[rand_inf]\n",
        "rand_uninf = np.random.randint(0, len(os.listdir(uninfected_folder)))\n",
        "uninf_pic = os.listdir(uninfected_folder)[rand_uninf]\n",
        "\n",
        "# Load sample images\n",
        "inf_load = Image.open(infected_folder + inf_pic)\n",
        "uninf_load = Image.open(uninfected_folder + uninf_pic)\n",
        "\n",
        "# Plot the sample images\n",
        "f = plt.figure(figsize=(10, 6))\n",
        "a1 = f.add_subplot(1, 2, 1)\n",
        "img_plot = plt.imshow(inf_load)\n",
        "a1.set_title('Infected Cell')\n",
        "\n",
        "a2 = f.add_subplot(1, 2, 2)\n",
        "img_plot = plt.imshow(uninf_load)\n",
        "a2.set_title('Uninfected Cell')\n",
        "\n",
        "# Data Preprocessing with ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.2)\n",
        "\n",
        "# Training Data\n",
        "trainDatagen = datagen.flow_from_directory(directory='../input/cell-images-for-detecting-malaria/cell_images/',\n",
        "                                           target_size=(width, height),\n",
        "                                           class_mode='binary',\n",
        "                                           batch_size=16,\n",
        "                                           subset='training')\n",
        "\n",
        "# Validation Data\n",
        "valDatagen = datagen.flow_from_directory(directory='../input/cell-images-for-detecting-malaria/cell_images/',\n",
        "                                          target_size=(width, height),\n",
        "                                          class_mode='binary',\n",
        "                                          batch_size=16,\n",
        "                                          subset='validation')\n",
        "\n",
        "# CNN Model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "cnn_model = model.fit(trainDatagen,\n",
        "                      steps_per_epoch=len(trainDatagen),\n",
        "                      epochs=20,\n",
        "                      validation_data=valDatagen,\n",
        "                      validation_steps=len(valDatagen))\n",
        "\n",
        "# Evaluate the training and validation accuracy\n",
        "plt.plot(cnn_model.history['accuracy'])\n",
        "plt.plot(cnn_model.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training set', 'Validation set'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss\n",
        "plt.plot(cnn_model.history['loss'])\n",
        "plt.plot(cnn_model.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training set', 'Validation set'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "w6TPw61jmN31",
        "outputId": "aec13b85-d9ab-4ae6-c49a-62b8804fcee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/iarunava/cell-images-for-detecting-malaria?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 675M/675M [00:08<00:00, 86.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/iarunava/cell-images-for-detecting-malaria/versions/1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../input/cell-images-for-detecting-malaria/cell_images/Parasitized/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5f9d461cad2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Check dataset sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Infected images count:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfected_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Uninfected images count:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninfected_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/cell-images-for-detecting-malaria/cell_images/Parasitized/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Downloading the dataset using KaggleHub\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"iarunava/cell-images-for-detecting-malaria\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Corrected dataset folder paths after downloading\n",
        "infected_folder = '/root/.cache/kagglehub/datasets/iarunava/cell-images-for-detecting-malaria/versions/1/cell_images/Parasitized/'\n",
        "uninfected_folder = '/root/.cache/kagglehub/datasets/iarunava/cell-images-for-detecting-malaria/versions/1/cell_images/Uninfected/'\n",
        "\n",
        "# Check dataset sizes\n",
        "print(\"Infected images count:\", len(os.listdir(infected_folder)))\n",
        "print(\"Uninfected images count:\", len(os.listdir(uninfected_folder)))\n",
        "\n",
        "# Display sample images\n",
        "rand_inf = np.random.randint(0, len(os.listdir(infected_folder)))\n",
        "inf_pic = os.listdir(infected_folder)[rand_inf]\n",
        "rand_uninf = np.random.randint(0, len(os.listdir(uninfected_folder)))\n",
        "uninf_pic = os.listdir(uninfected_folder)[rand_uninf]\n",
        "\n",
        "# Load sample images\n",
        "inf_load = Image.open(infected_folder + inf_pic)\n",
        "uninf_load = Image.open(uninfected_folder + uninf_pic)\n",
        "\n",
        "# Plot the sample images\n",
        "f = plt.figure(figsize=(10, 6))\n",
        "a1 = f.add_subplot(1, 2, 1)\n",
        "img_plot = plt.imshow(inf_load)\n",
        "a1.set_title('Infected Cell')\n",
        "\n",
        "a2 = f.add_subplot(1, 2, 2)\n",
        "img_plot = plt.imshow(uninf_load)\n",
        "a2.set_title('Uninfected Cell')\n",
        "\n",
        "# Set image size\n",
        "width = 128\n",
        "height = 128\n",
        "\n",
        "# Image preprocessing using ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.2)\n",
        "\n",
        "# Train data generator\n",
        "trainDatagen = datagen.flow_from_directory(directory='/root/.cache/kagglehub/datasets/iarunava/cell-images-for-detecting-malaria/versions/1/cell_images/',\n",
        "                                           target_size=(width, height),\n",
        "                                           class_mode='binary',\n",
        "                                           batch_size=16,\n",
        "                                           subset='training')\n",
        "\n",
        "# Validation data generator\n",
        "valDatagen = datagen.flow_from_directory(directory='/root/.cache/kagglehub/datasets/iarunava/cell-images-for-detecting-malaria/versions/1/cell_images/',\n",
        "                                           target_size=(width, height),\n",
        "                                           class_mode='binary',\n",
        "                                           batch_size=16,\n",
        "                                           subset='validation')\n",
        "\n",
        "# Create CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# First Convolutional layer\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Second Convolutional layer\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Third Convolutional layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Flatten and Dense layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on the data\n",
        "cnn_model = model.fit(\n",
        "    trainDatagen,\n",
        "    steps_per_epoch=len(trainDatagen),\n",
        "    epochs=20,\n",
        "    validation_data=valDatagen,\n",
        "    validation_steps=len(valDatagen)\n",
        ")\n",
        "\n",
        "# Plot model accuracy and loss over epochs\n",
        "plt.plot(cnn_model.history['accuracy'])\n",
        "plt.plot(cnn_model.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training set', 'Validation set'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cnn_model.history['loss'])\n",
        "plt.plot(cnn_model.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training set', 'Validation set'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "O6afhXu6mpEg",
        "outputId": "0ca2f7b6-f8eb-4370-8282-567e4a9b0dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ce78e661c1c8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Downloading the dataset using KaggleHub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import os\n",
        "\n",
        "# 📂 **Dataset Path**\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/iarunava/cell-images-for-detecting-malaria/versions/1/cell_images\"\n",
        "\n",
        "# 🚨 **Check & Fix Dataset**\n",
        "class_names = os.listdir(dataset_path)  # Check classes\n",
        "print(f\"Classes found: {class_names}\")\n",
        "\n",
        "# ✅ **Ensure Only 2 Classes Exist**\n",
        "assert \"Parasitized\" in class_names and \"Uninfected\" in class_names, \"Dataset should have only 'Parasitized' and 'Uninfected'!\"\n",
        "\n",
        "# 🔄 **Data Preprocessing**\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',  # ✅ Binary classification\n",
        "    classes=[\"Parasitized\", \"Uninfected\"],  # ✅ Explicitly define classes\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    classes=[\"Parasitized\", \"Uninfected\"],\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# 🏗 **Define CNN Model**\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # ✅ Binary classification\n",
        "])\n",
        "\n",
        "# 🛠 **Compile Model**\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',  # ✅ Correct loss for 2-class classification\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 🎯 **Train Model**\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 💾 **Save Model**\n",
        "model.save(\"malaria_classification_model.h5\")\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dONNrVE2ntu8",
        "outputId": "84445d00-e0ee-411b-c069-2125849ee0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes found: ['Parasitized', 'Uninfected', 'cell_images']\n",
            "Found 22048 images belonging to 2 classes.\n",
            "Found 5510 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 42ms/step - accuracy: 0.7466 - loss: 0.4830 - val_accuracy: 0.9459 - val_loss: 0.1748\n",
            "Epoch 2/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 39ms/step - accuracy: 0.9565 - loss: 0.1405 - val_accuracy: 0.9372 - val_loss: 0.1792\n",
            "Epoch 3/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 39ms/step - accuracy: 0.9584 - loss: 0.1272 - val_accuracy: 0.9485 - val_loss: 0.1527\n",
            "Epoch 4/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 40ms/step - accuracy: 0.9622 - loss: 0.1188 - val_accuracy: 0.9483 - val_loss: 0.1546\n",
            "Epoch 5/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 43ms/step - accuracy: 0.9647 - loss: 0.1100 - val_accuracy: 0.9479 - val_loss: 0.1612\n",
            "Epoch 6/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 43ms/step - accuracy: 0.9669 - loss: 0.1015 - val_accuracy: 0.9492 - val_loss: 0.1569\n",
            "Epoch 7/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 40ms/step - accuracy: 0.9685 - loss: 0.0947 - val_accuracy: 0.9461 - val_loss: 0.1643\n",
            "Epoch 8/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 40ms/step - accuracy: 0.9691 - loss: 0.0896 - val_accuracy: 0.9410 - val_loss: 0.1816\n",
            "Epoch 9/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 41ms/step - accuracy: 0.9718 - loss: 0.0818 - val_accuracy: 0.9457 - val_loss: 0.1997\n",
            "Epoch 10/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 48ms/step - accuracy: 0.9798 - loss: 0.0643 - val_accuracy: 0.9483 - val_loss: 0.1760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    }
  ]
}